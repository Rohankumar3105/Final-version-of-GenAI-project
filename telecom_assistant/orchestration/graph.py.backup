def llamaindex_node(state: TelecomAssistantState) -> TelecomAssistantState:
    """LlamaIndex knowledge retrieval agent"""
    try:
        from agents.knowledge_agents import process_knowledge_query
        
        response = process_knowledge_query(
            query=state["query"],
            customer_info=state["customer_info"]
        )
        
        print(f" LlamaIndex processing complete")
        
        return {
            **state,
            "intermediate_responses": {"llamaindex": response},
            "error": None
        }
    except Exception as e:
        error_message = f"Knowledge retrieval error: {str(e)}"
        print(f" Error in LlamaIndex node: {e}")
        
        return {
            **state,
            "intermediate_responses": {"llamaindex": f"I encountered an error accessing the knowledge base: {str(e)}"},
            "error": error_message
        }


def classify_query(state: TelecomAssistantState) -> TelecomAssistantState:
    """
    Classify the user's query into one of four categories using LLM.
    Categories:
    - billing_account: Billing and account queries
    - network_troubleshooting: Network issues
    - service_recommendation: Plan recommendations
    - knowledge_retrieval: Technical documentation queries
    """
    query = state["query"]
    customer_info = state.get("customer_info", {})

    # Create classification prompt
    classification_prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """You are a query classifier for a telecom service assistant.
        
Classify the user's query into ONE of these categories:

1. billing_account - Queries about bills, charges, payments, account status, plan costs
   Examples: "Why is my bill higher?", "What are the charges on my bill?", "How much do I owe?"

2. network_troubleshooting - Queries about network issues, connectivity, signal problems
   Examples: "I can't make calls", "My data is slow", "No network signal"

3. service_recommendation - Queries about plan recommendations, upgrades, finding best plans
   Examples: "Best plan for family?", "Which plan has international roaming?", "I need more data"

4. knowledge_retrieval - Queries about technical setup, configuration, how-to questions
   Examples: "How to enable VoLTE?", "What are APN settings?", "5G coverage areas?"

Respond with ONLY the category name, nothing else.
Category must be one of: billing_account, network_troubleshooting, service_recommendation, knowledge_retrieval""",
            ),
            ("user", "Query: {query}"),
        ]
    )

    try:
        # Get classification from LLM
        chain = classification_prompt | classifier_llm
        response = chain.invoke({"query": query})
        classification = response.content.strip().lower()

        # Validate classification
        valid_categories = [
            "billing_account",
            "network_troubleshooting",
            "service_recommendation",
            "knowledge_retrieval",
        ]

        if classification not in valid_categories:
            # Default to knowledge_retrieval if unclear
            classification = "knowledge_retrieval"

        print(f"âœ… Query classified as: {classification}")

        return {
            **state,
            "classification": classification,
            "error": None,
        }

    except Exception as e:
        print(f"âŒ Classification error: {e}")
        return {
            **state,
            "classification": "knowledge_retrieval",  # Default fallback
            "error": f"Classification error: {str(e)}",
        }


def route_query(state: TelecomAssistantState) -> str:
    """
    Route the query to the appropriate node based on classification.
    Returns the name of the next node to execute.
    """
    classification = state.get("classification", "")

    routing_map = {
        "billing_account": "crew_ai_node",
        "network_troubleshooting": "autogen_node",
        "service_recommendation": "langchain_node",
        "knowledge_retrieval": "llamaindex_node",
    }

    next_node = routing_map.get(classification, "fallback_handler")
    print(f"ðŸ”€ Routing to: {next_node}")

    return next_node


def crew_ai_node(state: TelecomAssistantState) -> TelecomAssistantState:
    """
    Handle billing and account queries using CrewAI.
    Uses Billing Specialist and Service Advisor agents.
    """
    query = state["query"]
    customer_info = state.get("customer_info", {})
    customer_id = customer_info.get("customer_id", "Unknown")

    print(f"ðŸ’¼ CrewAI Node processing billing query for customer: {customer_id}")

    try:
        # Import high-level billing handler from agents
        from agents.billing_agents import process_billing_query

        # Process the query using CrewAI billing agents (CrewAI-only implementation)
        response = process_billing_query(
            customer_id=customer_id,
            query=query,
            customer_info=customer_info,
        )
        

        print("âœ… CrewAI processing complete")

        return {
            **state,
            "intermediate_responses": {"crew_ai": response},
            "error": None,
        }

    except Exception as e:
        print(f"âŒ Error in CrewAI node: {e}")

        # Fallback response
        customer_name = customer_info.get("name", "Valued Customer")
        error_response = (
            f"I apologize, {customer_name}, but I encountered an error while "
            f"analyzing your billing information. "
            f"Please contact our billing department for assistance with your billing query: '{query}'"
        )

        return {
            **state,
            "intermediate_responses": {"crew_ai": error_response},
            "error": f"CrewAI error: {str(e)}",
        }


def autogen_node(state: TelecomAssistantState) -> TelecomAssistantState:
    """
    Handle network troubleshooting using AutoGen.
    TODO: Implement AutoGen multi-agent system
    """
    query = state["query"]
    customer_info = state.get("customer_info", {})

    print("ðŸ“¡ AutoGen Node processing network issue")

    # Mock response for now
    response = f"""**Network Diagnostics Report**

**Issue:** {query}
**Customer:** {customer_info.get('name', 'Valued Customer')}

**Diagnostic Steps:**
1. âœ… Checking network status in your area
2. âœ… Analyzing tower connectivity
3. âœ… Reviewing device compatibility

**Preliminary Findings:**
Our network specialists would provide:
- Current network status in your location
- Known outages or maintenance
- Device-specific troubleshooting steps
- Signal strength analysis

**Recommended Actions:**
- Step-by-step troubleshooting guide
- Configuration adjustments if needed
- Escalation to technical support if required

*[This is a mock response. Full AutoGen implementation pending.]*"""

    return {
        **state,
        "intermediate_responses": {"autogen": response},
    }


def langchain_node(state: TelecomAssistantState) -> TelecomAssistantState:
    """
    Handle service recommendations using LangChain ReAct agent.
    TODO: Implement LangChain agent with SQLDatabaseTool
    """
    query = state["query"]
    customer_info = state.get("customer_info", {})

    print("ðŸŽ¯ LangChain Node processing service recommendation")

    # Mock response for now
    response = f"""**Personalized Plan Recommendation**

**Your Requirements:** {query}
**Current Plan:** {customer_info.get('plan_id', 'N/A')}

**Analysis:**
Our recommendation engine would analyze:
- Your current usage patterns
- Specific requirements mentioned
- Available plans and features
- Cost-benefit comparison

**Recommended Plans:**
Based on your needs, we would suggest:
1. **Plan Option 1** - Best value for your usage
2. **Plan Option 2** - Premium features
3. **Plan Option 3** - Budget-friendly alternative

Each recommendation would include:
- Monthly cost breakdown
- Key features and benefits
- Comparison with current plan
- Potential savings or upgrades

*[This is a mock response. Full LangChain implementation pending.]*"""

    return {
        **state,
        "intermediate_responses": {"langchain": response},
    }


def llamaindex_node(state: TelecomAssistantState) -> TelecomAssistantState:
    """LlamaIndex knowledge retrieval agent"""
    try:
        from agents.knowledge_agents import process_knowledge_query
        
        response = process_knowledge_query(
            query=state["query"],
            customer_info=state["customer_info"]
        )
        
        print(f"✅ LlamaIndex processing complete")
        
        return {
            **state,
            "intermediate_responses": {"llamaindex": response},
            "error": None
        }
    except Exception as e:
        error_message = f"Knowledge retrieval error: {str(e)}"
        print(f"❌ Error in LlamaIndex node: {e}")
        
        return {
            **state,
            "intermediate_responses": {"llamaindex": f"I encountered an error accessing the knowledge base: {str(e)}"},
            "error": error_message
        }


def fallback_handler(state: TelecomAssistantState) -> TelecomAssistantState:
    """
    Handle queries that don't fit other categories or when errors occur.
    """
    query = state["query"]

    print("âš ï¸ Fallback handler activated")

    response = """**How Can I Help You?**

I'm not quite sure how to categorize your question. I can help you with:

ðŸ“± **Billing & Accounts**
- Bill inquiries and charges
- Payment questions
- Account status

ðŸ“¡ **Network Issues**
- Connectivity problems
- Signal issues
- Call/data problems

ðŸŽ¯ **Plan Recommendations**
- Finding the best plan
- Plan upgrades
- Feature comparisons

ðŸ“š **Technical Support**
- Device setup
- Configuration help
- How-to guides

Could you please rephrase your question or specify which area you need help with?"""

    return {
        **state,
        "intermediate_responses": {"fallback": response},
    }


def formulate_response(state: TelecomAssistantState) -> TelecomAssistantState:
    """
    Create final response from intermediate results.
    Formats the response for presentation to the user.
    """
    intermediate_responses = state.get("intermediate_responses", {})
    classification = state.get("classification", "unknown")

    print("ðŸ“ Formulating final response")

    # Extract the response from whichever node was called
    if intermediate_responses:
        response_value = next(iter(intermediate_responses.values()))
    else:
        response_value = (
            "I apologize, but I couldn't process your request. Please try again."
        )

    # Add classification info for debugging (can be removed in production)
    debug_info = f"\n\n*Query Type: {classification.replace('_', ' ').title()}*"

    final_response = response_value + debug_info

    return {
        **state,
        "final_response": final_response,
    }


def create_graph():
    """
    Create and compile the LangGraph workflow.
    Returns a compiled graph ready to process queries.
    """
    print("ðŸ”§ Creating LangGraph workflow...")

    # Initialize the graph with our state schema
    workflow = StateGraph(TelecomAssistantState)

    # Add all nodes
    workflow.add_node("classify_query", classify_query)
    workflow.add_node("crew_ai_node", crew_ai_node)
    workflow.add_node("autogen_node", autogen_node)
    workflow.add_node("langchain_node", langchain_node)
    workflow.add_node("llamaindex_node", llamaindex_node)
    workflow.add_node("fallback_handler", fallback_handler)
    workflow.add_node("formulate_response", formulate_response)

    # Add conditional edges from classification to appropriate processing node
    workflow.add_conditional_edges(
        "classify_query",
        route_query,
        {
            "crew_ai_node": "crew_ai_node",
            "autogen_node": "autogen_node",
            "langchain_node": "langchain_node",
            "llamaindex_node": "llamaindex_node",
            "fallback_handler": "fallback_handler",
        },
    )

    # Add edges from each processing node to response formulation
    workflow.add_edge("crew_ai_node", "formulate_response")
    workflow.add_edge("autogen_node", "formulate_response")
    workflow.add_edge("langchain_node", "formulate_response")
    workflow.add_edge("llamaindex_node", "formulate_response")
    workflow.add_edge("fallback_handler", "formulate_response")

    # End after formulating response
    workflow.add_edge("formulate_response", END)

    # Set the entry point
    workflow.set_entry_point("classify_query")

    # Compile and return the graph
    compiled_graph = workflow.compile()

    print("âœ… LangGraph workflow created successfully!")

    return compiled_graph


